{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ca9252",
   "metadata": {},
   "source": [
    "# **Exercise 2: Estimate EPC counterfactuals under retrofit actions**\n",
    "\n",
    "## Overview\n",
    "\n",
    "In Exercise 1, we built descriptive models to understand which building characteristics are most associated with EPC performance. Here, we implement a simple *counterfactual (“what‑if”) analysis*:\n",
    "\n",
    "1. Fit a model that approximates the EPC current energy efficiency score (`CURRENT_ENERGY_EFFICIENCY`) from a set of features.\n",
    "2. Apply retrofit actions on a hold‑out set by changing EPC input variables (e.g., wall efficiency band), and predict the counterfactual EPC score.\n",
    "\n",
    "> **Note**: This does *not* predict realised post‑retrofit bills. It estimates how the EPC score would change under modified building characteristics, using a data‑driven approximation of the EPC calculation logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e953001b",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Load libraries and the EPC dataset. As in Exercise 1, we drop columns with missing values for simplicity (you can revisit this and use imputation later). The target (outcome) variable is `CURRENT_ENERGY_EFFICIENCY`. To avoid data leakage, be careful not to use any EPC output variables as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Plot defaults\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = (10, 3)\n",
    "\n",
    "def accuracy_metrics(actual, predictions):\n",
    "    ''' Estimate predictive accuracy metrics '''\n",
    "    actual_copy = actual.copy().reshape(-1,1)\n",
    "    predictions_copy = predictions.copy().reshape(-1,1)\n",
    "    \n",
    "    error = actual_copy - predictions_copy    \n",
    "    assert(error.shape[0] == len(actual_copy))\n",
    "    if error.ndim > 1:        \n",
    "        assert(error.shape[1] == 1)\n",
    "\n",
    "    mse = np.square(error).mean()\n",
    "    rmse = np.sqrt( mse )\n",
    "    mae = np.abs(error).mean()\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'MAE: {mae}')\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# Update path to your local folder containing certificates.csv\n",
    "path = 'C:\\\\Users\\\\ucbva19\\\\Git projects\\\\energy_analytics_built_env\\\\data raw\\\\epc-certificates-Islington'\n",
    "df = pd.read_csv(f\"{path}\\\\certificates.csv\")  # change path\n",
    "\n",
    "print(df.head())\n",
    "print(df.isna().sum())\n",
    "\n",
    "# For simplicity, drop columns with any NaNs (you can improve this later)\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "assert(df.isna().sum().sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97926d13",
   "metadata": {},
   "source": [
    "## Fit Predictive Models\n",
    "\n",
    "First, we train two predictive models and select the best one. As in Exercise 1, features should be based on building characteristics (geometry, built form, efficiency bands for fabric, heating, etc.), whereas EPC outputs (costs, energy consumption, ratings) should *not* be used as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'CURRENT_ENERGY_EFFICIENCY'\n",
    "\n",
    "# further separate features into numerical, categorical, and ordinal\n",
    "numerical_features = ['TOTAL_FLOOR_AREA', 'FIXED_LIGHTING_OUTLETS_COUNT', 'LOW_ENERGY_LIGHTING']\n",
    "ordinal_features = ['WALLS_ENERGY_EFF', 'MAINHEAT_ENERGY_EFF', 'LIGHTING_ENERGY_EFF', 'HOT_WATER_ENERGY_EFF', 'WINDOWS_ENERGY_EFF']\n",
    "categorical_features = ['PROPERTY_TYPE', 'BUILT_FORM']\n",
    "\n",
    "feature_list = numerical_features + ordinal_features + categorical_features\n",
    "\n",
    "Y = df[target_variable]\n",
    "X = df[feature_list]\n",
    "\n",
    "# Training/ test split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Preprocessing\n",
    "categories_list = [df['PROPERTY_TYPE'].unique(), df['BUILT_FORM'].unique()]\n",
    "\n",
    "ord_list =   [['Very Poor', 'Poor', 'Average', 'Good', 'Very Good'] for feat in ordinal_features]\n",
    "\n",
    "# create a preprocessor that implements one-hot and ordinal encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "                  (\"ord\", OrdinalEncoder(categories = ord_list), ordinal_features),\n",
    "                  (\"num\", \"passthrough\", numerical_features),])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf013743-6f5b-4c58-b8e3-3b7366003fec",
   "metadata": {},
   "source": [
    "We compare two models, namely, linear regression and extremely randomized trees (ExtraTrees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6086deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Linear Regression\n",
    "lr_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"regressor\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Model 2: ExtraTrees\n",
    "et_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"regressor\", ExtraTreesRegressor(\n",
    "            n_estimators=500, random_state=42, n_jobs=-1))])\n",
    "\n",
    "lr_model.fit(train_X, train_Y)\n",
    "et_model.fit(train_X, train_Y)\n",
    "\n",
    "pred_lr = lr_model.predict(test_X)\n",
    "pred_et = et_model.predict(test_X)\n",
    "\n",
    "print('Accuracy metrics LR')\n",
    "rmse_lr, mae_lr = accuracy_metrics(test_Y.values, pred_lr)\n",
    "\n",
    "print('Accuracy metrics ET')\n",
    "rmse_et, mae_et = accuracy_metrics(test_Y.values, pred_et)\n",
    "\n",
    "# Select the model with lower RMSE\n",
    "model = et_model if mae_et <= mae_lr else lr_model\n",
    "print(\"Selected model:\", type(model.named_steps['regressor']).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf0c3f",
   "metadata": {},
   "source": [
    "## Define retrofit actions (monotonic upgrades)\n",
    "\n",
    "We model retrofit actions by **upgrading efficiency bands** in a *monotonic* way.\n",
    "\n",
    "- A dwelling is *eligible* for an action if it is **below** the target band.\n",
    "- If the dwelling is already at or above the target, the action has **no effect**.\n",
    "\n",
    "This keeps counterfactuals sane (e.g., we never “downgrade” a building).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c209e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: upgrade a single ordinal feature to at least a target level\n",
    "\n",
    "EFF_ORDER = {\"Very Poor\": 1,\n",
    "             \"Poor\": 2,\n",
    "             \"Average\": 3,\n",
    "             \"Good\": 4,\n",
    "             \"Very Good\": 5}\n",
    "\n",
    "def upgrade_to_level(df_in, feature, target_level, order = EFF_ORDER):\n",
    "    df_out = df_in.copy()\n",
    "    idx_map = {v: i for i, v in enumerate(order)}\n",
    "\n",
    "    current = df_out[feature].astype(str)\n",
    "    current_idx = current.map(idx_map)\n",
    "    target_idx = idx_map[target_level]\n",
    "\n",
    "    eligible = current_idx < target_idx\n",
    "    df_out.loc[eligible, feature] = target_level\n",
    "    return df_out, eligible\n",
    "\n",
    "# Define retrofit actions (single-feature and multi-feature)\n",
    "actions = {\n",
    "    \"Upgrade lighting to Very Good\": {\n",
    "        \"LIGHTING_ENERGY_EFF\": \"Very Good\",\n",
    "    },\n",
    "    \"Upgrade walls to Good\": {\n",
    "        \"WALLS_ENERGY_EFF\": \"Good\",\n",
    "    },\n",
    "    \"Upgrade windows to Good\": {\n",
    "        \"WINDOWS_ENERGY_EFF\": \"Good\",\n",
    "    },\n",
    "    \"Upgrade main heating to Very Good\": {\n",
    "        \"MAINHEAT_ENERGY_EFF\": \"Very Good\",\n",
    "    },\n",
    "    \"Upgrade hot water to Good\": {\n",
    "        \"HOT_WATER_ENERGY_EFF\": \"Good\",\n",
    "    },\n",
    "    \"Package: fabric + heating\": {\n",
    "        \"WALLS_ENERGY_EFF\": \"Good\",\n",
    "        \"WINDOWS_ENERGY_EFF\": \"Good\",\n",
    "        \"MAINHEAT_ENERGY_EFF\": \"Very Good\",\n",
    "    },\n",
    "}\n",
    "\n",
    "list(actions.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7b88a",
   "metadata": {},
   "source": [
    "## Predict counterfactual EPC scores on hold‑out set\n",
    "\n",
    "For each action, we implement the following steps:\n",
    "1. Predict baseline EPC score on the hold‑out set.\n",
    "2. Apply the selected action (only improving eligible dwellings).\n",
    "3. Predict the counterfactual EPC score.\n",
    "4. Compute $\\Delta \\,\\text{score} = \\text{counterfactual} − \\text{baseline}$.\n",
    "\n",
    "Positive $\\Delta$ means the retrofit improves EPC score. Clearly, we anticipate that $\\Delta$ will be positive in most cases, although counterintuitive results are plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline predictions on holdout\n",
    "baseline_pred = model.predict(test_X)\n",
    "\n",
    "results = []\n",
    "per_action_deltas = {}  # store arrays for plotting\n",
    "\n",
    "# Iterate over potential actions\n",
    "for action_name, changes in actions.items():\n",
    "    X_cf = test_X.copy()\n",
    "    eligible_mask = np.ones(len(X_cf), dtype=bool)\n",
    "\n",
    "    print(f'Action: {action_name}')\n",
    "    \n",
    "    # Apply each feature upgrade; eligibility is the AND across features\n",
    "    for feat, target_level in changes.items():\n",
    "        X_cf, elig = upgrade_to_level(X_cf, feat, target_level)\n",
    "        eligible_mask &= elig.values\n",
    "\n",
    "    # Predict counterfactuals\n",
    "    cf_pred = model.predict(X_cf)\n",
    "\n",
    "    delta = cf_pred - baseline_pred\n",
    "    \n",
    "    # Keep only eligible dwellings\n",
    "    delta_eligible = delta[eligible_mask]\n",
    "\n",
    "    results.append({\n",
    "        \"action\": action_name,\n",
    "        \"eligible_n\": int(eligible_mask.sum()),\n",
    "        \"eligible_share\": float(eligible_mask.mean()),\n",
    "        \"mean_delta\": float(np.mean(delta_eligible)) if eligible_mask.sum() else np.nan,\n",
    "        \"median_delta\": float(np.median(delta_eligible)) if eligible_mask.sum() else np.nan,\n",
    "    })\n",
    "\n",
    "    per_action_deltas[action_name] = delta_eligible\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"mean_delta\", ascending=False)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0677cef7",
   "metadata": {},
   "source": [
    "## Visualise multiple actions\n",
    "\n",
    "We show:\n",
    "- Bar chart of mean $\\Delta$ score per action (eligible homes only)\n",
    "- Boxplot of the full distribution of $\\Delta$ score per action\n",
    "\n",
    "Actions with zero eligible homes are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8470934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to actions with eligible homes\n",
    "plot_actions = [a for a in actions.keys() if len(per_action_deltas[a]) > 0]\n",
    "\n",
    "means = [np.mean(per_action_deltas[a]) for a in plot_actions]\n",
    "counts = [len(per_action_deltas[a]) for a in plot_actions]\n",
    "\n",
    "# Bar chart: mean delta\n",
    "plt.figure(figsize=(10, 4.5))\n",
    "plt.bar(range(len(plot_actions)), means)\n",
    "plt.xticks(range(len(plot_actions)), plot_actions, rotation=35, ha='right')\n",
    "plt.ylabel(\"Mean Δ EPC score (eligible homes)\")\n",
    "plt.title(\"Average counterfactual improvement by action\")\n",
    "\n",
    "# Annotate eligible counts\n",
    "for i, c in enumerate(counts):\n",
    "    plt.text(i, means[i], f\"n={c}\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Boxplot: distributions\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.boxplot([per_action_deltas[a] for a in plot_actions], labels=plot_actions, showfliers=False)\n",
    "plt.xticks(rotation=35, ha='right')\n",
    "plt.ylabel(\"Δ EPC score (eligible homes)\")\n",
    "plt.title(\"Distribution of counterfactual improvement by action\")\n",
    "plt.axhline(0, linestyle='--', color='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238076f",
   "metadata": {},
   "source": [
    "## Optional: segment impacts by built form\n",
    "\n",
    "A useful next step is to see whether an action benefits some housing types more than others (e.g., flats vs terraces).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example segmentation for one action\n",
    "example_action = \"Upgrade walls to Good\"\n",
    "changes = actions[example_action]\n",
    "\n",
    "X_cf = test_X.copy()\n",
    "eligible_mask = np.ones(len(X_cf), dtype=bool)\n",
    "for feat, target_level in changes.items():\n",
    "    X_cf, elig = upgrade_to_level(X_cf, feat, target_level)\n",
    "    eligible_mask &= elig.values\n",
    "\n",
    "baseline = baseline_pred\n",
    "cf = model.predict(X_cf)\n",
    "delta = cf - baseline\n",
    "\n",
    "seg = pd.DataFrame({\n",
    "    \"BUILT_FORM\": test_X[\"BUILT_FORM\"].values,\n",
    "    \"delta\": delta,\n",
    "    \"eligible\": eligible_mask,\n",
    "})\n",
    "\n",
    "seg = seg[seg[\"eligible\"]]\n",
    "summary = seg.groupby(\"BUILT_FORM\")[\"delta\"].agg([\"count\", \"mean\", \"median\"]).sort_values(\"mean\", ascending=False)\n",
    "display(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
