{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac447a0-a43e-4115-98d3-19b057e1b3a5",
   "metadata": {},
   "source": [
    "# **Exercise 1: Analyzing Energy Performance of Buildings**\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this exercise, we analyze the [Energy Performance Certificate (EPC) dataset](https://epc.opendatacommunities.org/domestic/search) of individual dwellings in England and Wales. The EPC dataset records the *modelled* energy performance at the time of assessment, with each row corresponding to a single certificate issued following a standardised survey and calculation procedure, called [Standard Assessment Procedure (SAP)](https://www.gov.uk/guidance/standard-assessment-procedure). EPCs are model-based estimates under standard assumptions about weather, occupancy, and use, and *do not represent measured energy use*. EPC outputs are primarily designed for homeowners, renters, and policymakers.\n",
    "\n",
    "By the end of this exercise, you should be able to:\n",
    "- Process, visualize, and interpret building EPC data.\n",
    "- Use descriptive/predictive analytics to identify the main factors that drive EPC ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf79c47-f674-43d4-9536-0d7a861c9aa6",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Load the required Python libraries and the data set. The data set contains information from 5000 buildings located in the London borough of Islington and is stored ```...\\data raw\\epc-certificates-Islington```; file ```certificates.csv``` contains the data and ```columns.csv``` explains the colunm headers. To load the data, update the ```path``` variable to the local folder location. \n",
    "\n",
    "For simplicity, columns with ```NaN``` values are dropped. An auxiliary function that estimates predictive accuracy, namely, mean squared error (MSE), root mean squared error (RMSE), and mean absolute error (MAE), is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74114abd-175d-4e66-819b-486f9eaf50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def accuracy_metrics(actual, predictions):\n",
    "    ''' Estimate predictive accuracy metrics '''\n",
    "    actual_copy = actual.copy().reshape(-1,1)\n",
    "    predictions_copy = predictions.copy().reshape(-1,1)\n",
    "    \n",
    "    error = actual_copy - predictions_copy    \n",
    "    assert(error.shape[0] == len(actual_copy))\n",
    "    if error.ndim > 1:        \n",
    "        assert(error.shape[1] == 1)\n",
    "\n",
    "    mse = np.square(error).mean()\n",
    "    rmse = np.sqrt( mse )\n",
    "    mae = np.abs(error).mean()\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'MAE: {mae}')\n",
    "    return rmse, mae\n",
    "\n",
    "# default settings for plots\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "plt.rcParams['figure.figsize'] = (10,3)\n",
    "\n",
    "# load data\n",
    "# !!!! Update the path variable\n",
    "path = 'C:\\\\Users\\\\ucbva19\\\\Git projects\\\\energy_analytics_built_env\\\\data raw\\\\epc-certificates-Islington'\n",
    "df = pd.read_csv(f\"{path}\\\\certificates.csv\")  # change path\n",
    "\n",
    "print(df.isna().sum())\n",
    "display(df.head(3))\n",
    "\n",
    "# drop columns with NaNs\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "assert(df.isna().sum().sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79656024-924c-4ced-99ab-fcd97cc4473e",
   "metadata": {},
   "source": [
    "## Preliminary analysis\n",
    "\n",
    "As an example of preliminary analysis, we generate a few informative plots and descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166fe41-99d7-43f8-bea1-6b9a50c289ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "print(df['ENERGY_CONSUMPTION_CURRENT'].describe())\n",
    "print(df['HEATING_COST_CURRENT'].describe())\n",
    "print(df['CURRENT_ENERGY_RATING'].describe())\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure()\n",
    "plt.hist(df[\"ENERGY_CONSUMPTION_CURRENT\"], bins=200, density=True)\n",
    "plt.axvline(df[\"ENERGY_CONSUMPTION_CURRENT\"].mean(), linestyle=\"--\", color = 'black')\n",
    "plt.xlim(0, 3000)\n",
    "plt.title(\"ENERGY_CONSUMPTION distribution\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# EPC rating counts\n",
    "plt.figure()\n",
    "for k, g in df.groupby(\"CURRENT_ENERGY_RATING\"):\n",
    "    plt.hist(g[\"ENERGY_CONSUMPTION_CURRENT\"], bins=150, histtype=\"step\", label=str(k))\n",
    "plt.xlim(0, df[\"ENERGY_CONSUMPTION_CURRENT\"].quantile(0.99))\n",
    "plt.title(\"Consumption grouped by EPC rating\")\n",
    "plt.legend(ncol=2, fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot by EPC\n",
    "plt.figure()\n",
    "cats = sorted(df[\"CURRENT_ENERGY_RATING\"].dropna().unique())\n",
    "data = [df.loc[df[\"CURRENT_ENERGY_RATING\"] == c, \"ENERGY_CONSUMPTION_CURRENT\"].values for c in cats]\n",
    "plt.boxplot(data, labels = cats, showfliers=False)\n",
    "plt.title(\"Consumption by EPC rating (boxplot)\")\n",
    "plt.xlabel(\"EPC\")\n",
    "plt.ylabel(\"ENERGY_CONSUMPTION $(kWh/m^2)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524b19a-7638-4015-9071-8f665663d4a7",
   "metadata": {},
   "source": [
    "## Which factors drive EPC ratings?\n",
    "\n",
    "Our main task is to analyze the factors that drive EPC ratings. We will use ```CURRENT_ENERGY_EFFICIENCY``` as the target/ outcome variable, which is a dimensionless variable that takes values in the range $(0,100)$, where $100$ indicates the most efficient dwelling (effectively, zero energy costs).\n",
    "\n",
    "You may use any descriptive or predictive analytics method that you consider appropriate. There are multiple ways to tackle this problem. For instance, you can apply linear regression analysis and conduct statistical tests or train predictive machine learning (ML) models and calculate feature importance metrics, such as Shapley values.\n",
    "\n",
    "#### Avoiding data leakage\n",
    "\n",
    "Several variables in this dataset are model outputs, i.e., they are computed from the model itself. Using them as predictors should be avoided as it creates data leakage and circular logic. It is suggested to focus on features that relate to building characteristics, such as built form, fabric, services, and so forth. \n",
    "\n",
    "Here is a list of recommended features (feel free to include more):\n",
    "- Built form: ```TOTAL_FLOOR_AREA```, ```PROPERTY_TYPE```, ```BUILT_FORM```, and ```FLOOR_HEIGHT```\n",
    "- Envelope: ```WALLS_ENERGY_EFF``` and ```WINDOWS_ENERGY_EFF```\n",
    "- Heating and hot water: ```MAINHEAT_ENERGY_EFF``` and ```HOT_WATER_ENERGY_EFF```\n",
    "- Lighting and auxiliary: ```LIGHTING_ENERGY_EFF```, ```FIXED_LIGHTING_OUTLETS_COUNT``` and ```LOW_ENERGY_LIGHTING```\n",
    "\n",
    "Note that variables such as ```WALLS_ENERGY_EFF``` or ```MAINHEAT_ENERGY_EFF``` are categorical SAP-derived efficiency bands (e.g. Poor / Average / Good), not measured efficiencies.\n",
    "\n",
    "Variables about efficiency, rating, costs, or counterfactuals (marked with ```POTENTIAL```) *should not* be used as predictors. For instance, do not use ```CURRENT_ENERGY_EFFICIENCY, CURRENT_ENERGY_RATING, ENERGY_CONSUMPTION_CURRENT, CO2_EMISSIONS_CURRENT, ENVIRONMENT_IMPACT_CURRENT, HEATING_COST_CURRENT, HOT_WATER_COST_CURRENT, LIGHTING_COST_CURRENT, POTENTIAL_ENERGY_EFFICIENCY, POTENTIAL_ENERGY_RATING, ENERGY_CONSUMPTION_POTENTIAL``` and ```CO2_EMISSIONS_POTENTIAL```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634ac34-3e51-46ee-8804-21bc38e1ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'CURRENT_ENERGY_EFFICIENCY'\n",
    "feature_list = ['TOTAL_FLOOR_AREA', 'PROPERTY_TYPE', 'BUILT_FORM',\n",
    "                'WALLS_ENERGY_EFF', 'WINDOWS_ENERGY_EFF', \n",
    "                'MAINHEAT_ENERGY_EFF', 'HOT_WATER_ENERGY_EFF',\n",
    "                'LIGHTING_ENERGY_EFF', 'FIXED_LIGHTING_OUTLETS_COUNT', 'LOW_ENERGY_LIGHTING']\n",
    "\n",
    "Y = df[target_variable]\n",
    "X = df[feature_list]\n",
    "\n",
    "# print out categories for categorical features\n",
    "for c in feature_list:\n",
    "    if pd.api.types.is_string_dtype(df[c]): \n",
    "        print(f'Feature: {c}')\n",
    "        print(f'Categories: {X[c].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6670a-be3f-47f0-a4f6-e13d6f0b0548",
   "metadata": {},
   "source": [
    "### Solution: Tree-based regression + Permutation Importance\n",
    "\n",
    "We approach this problem using an ML predictor and estimating the importance of each feature. For this example, we choose the ```ExtraTreesRegressor``` predictor from the ```sklearn``` library and estimate the [Permutation Importance](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance) metric, which is a modeling inspection method that works with any trained predictor. An illustrative example and explanation can be found [here](https://scikit-learn.org/stable/modules/permutation_importance.html). In short, given a trained model, each feature (column) observation is randomly shuffled (permutated) and predictive performance is evaluated on a hold-out set. The shuffling process resembles adding noise and renders each feature effectively useless; the expected decrease in predictive accuracy is a good proxy for the importance of each feature.\n",
    "\n",
    "The code below implements the following steps:\n",
    "- Features are seperated into numerical, categorical, and ordinal features. Categorical features are one-hot encoded using ```OneHotEncoder``` and ordinal features are encoded using ```OrdinalEncoder```.\n",
    "- To streamline the preprocessing, a ```ColumnTransformer``` and a ```Pipeline``` object are created.\n",
    "- Data are split into train/test set and the ExtraTree regressor is trained.\n",
    "- The Permutation Importance method is applied.\n",
    "\n",
    "Tree-based methods estimate an internal feature importance metric during training, based on expected error reduction when splitting an internal node, which is plotted as well.  However, this metric is known to be biased. Comparing the two plots, we observe that the most important feature differs from the one obtained using the Permutation Importance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b84c8-d289-4980-852b-a887456f34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Step 1: Pre-process and fit regression model\n",
    "\n",
    "# Load libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "target_variable = 'CURRENT_ENERGY_EFFICIENCY'\n",
    "\n",
    "# further separate features into numerical, categorical, and ordinal\n",
    "numerical_features = ['TOTAL_FLOOR_AREA', 'FIXED_LIGHTING_OUTLETS_COUNT', 'LOW_ENERGY_LIGHTING']\n",
    "ordinal_features = ['WALLS_ENERGY_EFF', 'MAINHEAT_ENERGY_EFF', 'LIGHTING_ENERGY_EFF', 'HOT_WATER_ENERGY_EFF', 'WINDOWS_ENERGY_EFF']\n",
    "categorical_features = ['PROPERTY_TYPE', 'BUILT_FORM']\n",
    "\n",
    "feature_list = numerical_features + ordinal_features + categorical_features\n",
    "\n",
    "Y = df[target_variable]\n",
    "X = df[feature_list]\n",
    "\n",
    "# Training/ test split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Preprocessing\n",
    "categories_list = [df['PROPERTY_TYPE'].unique(), df['BUILT_FORM'].unique()]\n",
    "\n",
    "ord_list =   [['Very Poor', 'Poor', 'Average', 'Good', 'Very Good'] for feat in ordinal_features]\n",
    "\n",
    "# create a preprocessor that implements one-hot and ordinal encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "                  (\"ord\", OrdinalEncoder(categories = ord_list), ordinal_features),\n",
    "                  (\"num\", \"passthrough\", numerical_features),])\n",
    "\n",
    "# ExtraTree Model pipeline\n",
    "et_model = Pipeline(\n",
    "    steps=[(\"preprocess\", preprocessor), (\"regressor\", ExtraTreesRegressor()),])\n",
    "\n",
    "et_model.fit(train_X, train_Y)\n",
    "y_et_pred = et_model.predict(test_X)\n",
    "\n",
    "# evaluate accuracy\n",
    "print('Evaluate model on out-of-sample data')\n",
    "_, _ = accuracy_metrics(test_Y.values, y_et_pred)\n",
    "\n",
    "# Permutation importance\n",
    "r = permutation_importance(et_model, test_X, test_Y, n_repeats=30, random_state=0)\n",
    "sorted_importances_idx = r.importances_mean.argsort()\n",
    "importances = pd.DataFrame( r.importances[sorted_importances_idx].T, columns = X.columns[sorted_importances_idx],)\n",
    "\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "plt.show()\n",
    "\n",
    "# Feature importance (default estimation in tree-based algorithms)\n",
    "# get feature names after one-hot encoding\n",
    "feature_names = et_model.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "importances = et_model.named_steps[\"regressor\"].feature_importances_\n",
    "\n",
    "fi = pd.Series(importances, index = feature_names).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "fi.head(15).plot(kind=\"barh\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature importance (ExtraTrees)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbe52b-a3f2-48bc-b2ab-4d41f940709f",
   "metadata": {},
   "source": [
    "Both approaches indicate that ```WALLS_ENERGY_EFF``` is the most important feature. Our results corroborate findings from existing studies. For instance, [1] finds that external wall U-value and dwelling geometry account for 75% of the variance of the energy rating of gas central-heated houses in England.\n",
    "\n",
    "#### References\n",
    "\n",
    "1. Stone, A., Shipworth, D., Biddulph, P. and Oreszczyn, T., 2014. Key factors determining the energy rating of existing English houses. Building Research & Information, 42(6), pp.725-738."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
